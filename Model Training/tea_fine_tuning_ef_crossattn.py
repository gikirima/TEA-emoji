# -*- coding: utf-8 -*-
"""TEA_Fine_Tuning_EF_CrossAttn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DIYzrl_hPRWkd-bdiRi7JLcIV2Bi82JS

# STEP 0: INSTALL AND IMPORT LIBRARIES
## Install necessary libraries from Hugging Face, scikit-learn, etc.
"""

!pip install wandb transformers datasets scikit-learn scikit-multilearn emoji torch --quiet

import pandas as pd
import torch
import torch.nn as nn
import emoji
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments
from datasets import Dataset
from skmultilearn.model_selection import iterative_train_test_split
from dataclasses import dataclass
from transformers.tokenization_utils_base import PaddingStrategy, PreTrainedTokenizerBase
from typing import Any, Dict, List, Optional, Union

"""# STEP 1: LOAD DATASET
## Ensure 'dataset.csv' is available in your environment.
"""

try:
    df = pd.read_csv('https://raw.githubusercontent.com/gikirima/TEA-emoji/refs/heads/main/dataset_emoji_only.csv')
    print("Dataset loaded successfully.")
except FileNotFoundError:
    print("Error: not found. Please upload the file.")
    exit()

"""# STEP 2: EMOJI EXTRACTION & VOCABULARY CREATION
## Scan the dataset to build a vocabulary of unique emojis.
"""

print("\nScanning dataset for unique emojis...")
unique_emojis = set()
for text in df['text'].dropna():
    text_str = str(text)
    for character in text_str:
        if emoji.is_emoji(character):
            unique_emojis.add(character)

# Create a mapping from emoji to integer ID. ID 0 is reserved for padding.
emoji_list = sorted(list(unique_emojis))
emoji_to_id = {em: i for i, em in enumerate(emoji_list, 1)}
emoji_to_id['<PAD>'] = 0
id_to_emoji = {i: em for em, i in emoji_to_id.items()}
EMOJI_VOCAB_SIZE = len(emoji_to_id)
EMOJI_PAD_ID = emoji_to_id['<PAD>']

print(f"Found {len(unique_emojis)} unique emojis.")
print(f"Emoji vocabulary size (including <PAD>): {EMOJI_VOCAB_SIZE}")

"""# STEP 3: DEFINE CUSTOM MODEL (EARLY FUSION WITH CROSS-ATTENTION)
## This model architecture is based on the provided diagram.
"""

class BertEmojiCrossAttentionModel(nn.Module):
    """
    Custom model fusing IndoBERT and emoji embeddings via cross-attention.

    The text's hidden states act as the 'query', while the emoji embeddings
    act as the 'key' and 'value'. The model then fuses the original text
    summary ([CLS] token) with the new emoji-aware text summary.
    """
    def __init__(self, model_name, num_labels, emoji_vocab_size, emoji_emb_dim=256, num_attention_heads=8, dropout_rate=0.2):
        super().__init__()
        self.num_labels = num_labels

        # 1. Base BERT model
        self.bert = AutoModel.from_pretrained(model_name)
        bert_hidden_size = self.bert.config.hidden_size

        # 2. Emoji processing layers
        self.emoji_embeddings = nn.Embedding(emoji_vocab_size, emoji_emb_dim, padding_idx=EMOJI_PAD_ID)
        self.emoji_projection = nn.Linear(emoji_emb_dim, bert_hidden_size)

        # 3. Cross-Attention layer
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=bert_hidden_size,
            num_heads=num_attention_heads,
            batch_first=True  # Crucial for Hugging Face model outputs
        )

        # 4. Classifier head (MLP)
        # Input is the concatenation of two [CLS] vectors, as per the diagram.
        self.classifier = nn.Sequential(
            nn.Linear(bert_hidden_size * 2, 512),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(512, num_labels)
        )

        # Compatibility with Hugging Face Trainer
        self.config = self.bert.config
        self.config.problem_type = "multi_label_classification"

    def forward(
        self,
        input_ids: torch.Tensor,
        attention_mask: torch.Tensor,
        emoji_ids: torch.Tensor,
        labels: Optional[torch.Tensor] = None
    ):
        # 1. Get raw text features from BERT
        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        text_hidden_states = bert_outputs.last_hidden_state  # Shape: [B, T, H]
        cls_text_only = text_hidden_states[:, 0, :] # [CLS] from raw text

        # 2. Get emoji features
        emoji_embs = self.emoji_embeddings(emoji_ids) # Shape: [B, E, Emb_Dim]
        projected_emoji_embs = self.emoji_projection(emoji_embs) # Shape: [B, E, H]

        # 3. Perform Cross-Attention
        # Query: Text hidden states
        # Key/Value: Projected emoji embeddings
        # We need a mask to ignore PAD emojis in the key/value pairs.
        emoji_padding_mask = (emoji_ids == EMOJI_PAD_ID) # Shape: [B, E]

        emoji_aware_hidden_states, _ = self.cross_attention(
            query=text_hidden_states,
            key=projected_emoji_embs,
            value=projected_emoji_embs,
            key_padding_mask=emoji_padding_mask
        ) # Shape: [B, T, H]
        cls_cross_attention = emoji_aware_hidden_states[:, 0, :] # [CLS] from emoji-aware states

        # 4. Fusion
        # Concatenate the two [CLS] representations as per the diagram
        fused_vector = torch.cat((cls_text_only, cls_cross_attention), dim=1) # Shape: [B, 2*H]

        # 5. Classification
        logits = self.classifier(fused_vector)

        # 6. Calculate loss if labels are provided
        loss = None
        if labels is not None:
            loss_fct = nn.BCEWithLogitsLoss()
            loss = loss_fct(logits, labels.float())

        return (loss, logits) if loss is not None else (logits,)

# --- Initialize Model and Tokenizer ---
model_name = "indobenchmark/indobert-base-p1"
label_columns = ['joy', 'trust', 'fear', 'surprise', 'sadness', 'disgust', 'anger', 'anticipation']
num_labels = len(label_columns)
EMOJI_EMBEDDING_DIM = 128

print(f"\nLoading tokenizer '{model_name}'...")
tokenizer = AutoTokenizer.from_pretrained(model_name)

print("Initializing custom model 'BertEmojiCrossAttentionModel'...")
model = BertEmojiCrossAttentionModel(
    model_name=model_name,
    num_labels=num_labels,
    emoji_vocab_size=EMOJI_VOCAB_SIZE,
    emoji_emb_dim=EMOJI_EMBEDDING_DIM
)
print("Model and tokenizer are ready.")

"""# STEP 4: PREPARE DATASET FOR HUGGING FACE
## Split data into training, validation, and test sets.
"""

print("\nSplitting dataset using iterative_train_test_split...")
X = df['text'].to_numpy().reshape(-1, 1)
y = df[label_columns].to_numpy()

# Stratified split for multi-label data
X_train_val, y_train_val, X_test, y_test = iterative_train_test_split(X, y, test_size=0.2)
X_train, y_train, X_val, y_val = iterative_train_test_split(X_train_val, y_train_val, test_size=0.2)

df_train = pd.DataFrame(X_train.flatten(), columns=['text'])
for i, col in enumerate(label_columns): df_train[col] = y_train[:, i]

df_val = pd.DataFrame(X_val.flatten(), columns=['text'])
for i, col in enumerate(label_columns): df_val[col] = y_val[:, i]

df_test = pd.DataFrame(X_test.flatten(), columns=['text'])
for i, col in enumerate(label_columns): df_test[col] = y_test[:, i]

print("\nConverting DataFrames to Hugging Face Datasets...")
train_dataset_hf = Dataset.from_pandas(df_train)
eval_dataset_hf = Dataset.from_pandas(df_val)
test_dataset_hf = Dataset.from_pandas(df_test)

# --- Preprocessing Function ---
def preprocess_data(examples):
    # 1. Tokenize text for BERT
    tokenized_output = tokenizer(
        examples["text"], padding=False, truncation=True, max_length=128
    )

    # 2. Extract and map emojis to their IDs
    all_emoji_ids = []
    texts = [str(t) for t in examples["text"]]
    for text in texts:
        ids = [emoji_to_id.get(char) for char in text if emoji.is_emoji(char) and char in emoji_to_id]
        ids = [id for id in ids if id is not None]
        if not ids:
            ids = [EMOJI_PAD_ID] # Use a single PAD token if no emojis are present
        all_emoji_ids.append(ids)

    # 3. Format labels
    labels = [[float(examples[label][i]) for label in label_columns] for i in range(len(texts))]

    tokenized_output["emoji_ids"] = all_emoji_ids
    tokenized_output["labels"] = labels
    return tokenized_output

print("\nTokenizing text and extracting emojis for all datasets...")
train_dataset = train_dataset_hf.map(preprocess_data, batched=True, remove_columns=train_dataset_hf.column_names)
eval_dataset = eval_dataset_hf.map(preprocess_data, batched=True, remove_columns=eval_dataset_hf.column_names)
test_dataset = test_dataset_hf.map(preprocess_data, batched=True, remove_columns=test_dataset_hf.column_names)

print("\n--- Data Splitting and Preprocessing Complete ---")
print(f"Training data count: {len(train_dataset)}")
print(f"Validation data count: {len(eval_dataset)}")
print(f"Test data count: {len(test_dataset)}")

"""# STEP 4.5: CREATE CUSTOM DATA COLLATOR
## This collator handles dynamic padding for both text and emoji ID sequences.
"""

@dataclass
class CustomDataCollator:
    tokenizer: PreTrainedTokenizerBase
    padding: Union[bool, str, PaddingStrategy] = True
    max_length: Optional[int] = None
    pad_to_multiple_of: Optional[int] = None

    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:
        labels = [feature.pop("labels") for feature in features]
        emoji_ids = [feature.pop("emoji_ids") for feature in features]

        # Use the tokenizer's default padding for text-based inputs
        batch = self.tokenizer.pad(
            features,
            padding=self.padding,
            max_length=self.max_length,
            pad_to_multiple_of=self.pad_to_multiple_of,
            return_tensors="pt",
        )

        # Manually pad the emoji_ids sequences
        max_emoji_len = max(len(ids) for ids in emoji_ids)
        padded_emoji_ids = [ids + [EMOJI_PAD_ID] * (max_emoji_len - len(ids)) for ids in emoji_ids]

        # Add the padded data back to the batch
        batch["labels"] = torch.tensor(labels, dtype=torch.float)
        batch["emoji_ids"] = torch.tensor(padded_emoji_ids, dtype=torch.long)

        return batch

data_collator = CustomDataCollator(tokenizer=tokenizer)

"""# STEP 5: DEFINE EVALUATION METRICS
## Function to compute performance metrics for multi-label classification.
"""

def compute_metrics(p):
    logits, labels = p
    preds_proba = torch.sigmoid(torch.tensor(logits))
    # Use a 0.5 threshold to binarize predictions
    preds = (preds_proba > 0.5).int().numpy()
    labels = labels.astype(int)

    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)
    f1_micro = f1_score(labels, preds, average='micro', zero_division=0)
    precision_micro = precision_score(labels, preds, average='micro', zero_division=0)
    recall_micro = recall_score(labels, preds, average='micro', zero_division=0)

    return {
        'f1_macro': f1_macro,
        'f1_micro': f1_micro,
        'precision_micro': precision_micro,
        'recall_micro': recall_micro,
        'accuracy': accuracy_score(labels, preds), # Exact match ratio
    }

"""# STEP 6: CONFIGURE AND RUN TRAINING
## Set up training arguments and initialize the Hugging Face Trainer.
"""

# WANDB integration for experiment tracking.
try:
    from google.colab import userdata
    wandb_api_key = userdata.get('WANDB_API_KEY')
    import wandb
    if wandb_api_key:
        wandb.login(key=wandb_api_key)
        print("WANDB login successful.")
        wandb.init(
            project="EF_CrossAttention_Model",
            name="training_run_8",
        )
        report_to = "wandb"
    else:
        print("WANDB_API key not found. Skipping WANDB logging.")
        report_to = "none"
except (ImportError, KeyError):
    print("Not in Colab or WANDB key not set. Skipping WANDB logging.")
    report_to = "none"


training_args = TrainingArguments(
    output_dir="./results_cross_attention",
    eval_strategy="steps",
    save_strategy="steps",
    load_best_model_at_end=True,
    metric_for_best_model="f1_macro",
    greater_is_better=True,
    logging_steps=250,
    eval_steps=1500,
    save_steps=1500,
    save_total_limit=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=4,
    learning_rate=3e-5,
    warmup_steps=500,
    weight_decay=0.01,
    fp16=True, # Requires a GPU with Tensor Cores
    report_to=report_to
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

print("\nStarting model fine-tuning with Cross-Attention fusion...")
trainer.train()
print("\nTraining complete.")

"""# STEP 7: FINAL EVALUATION
## Evaluate the best model on the held-out test set.
"""

print("\nEvaluating the best model on the test set...")
evaluation_results = trainer.evaluate(eval_dataset=test_dataset)
print("\nFinal Evaluation Results:")
print(evaluation_results)

print("\nGenerating predictions for confusion matrix...")
prediction_output = trainer.predict(test_dataset)
logits = prediction_output.predictions
true_labels = prediction_output.label_ids
predictions = (torch.sigmoid(torch.from_numpy(logits)) > 0.5).int().numpy()

# --- Generate, Save, and Log Confusion Matrix Plot ---
final_model_path = "./fine_tuned_cross_attention_model"
os.makedirs(final_model_path, exist_ok=True)

print("\nCreating confusion matrix plots for each label...")
fig, axes = plt.subplots(2, 4, figsize=(20, 10))
axes = axes.flatten()
for i, label_name in enumerate(label_columns):
    cm = confusion_matrix(y_true=true_labels[:, i], y_pred=predictions[:, i])
    ax = axes[i]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
    ax.set_title(f"Confusion Matrix: {label_name.title()}", fontweight='bold')
    ax.set_xlabel('Predicted Label')
    ax.set_ylabel('True Label')

plt.tight_layout()
plot_path = os.path.join(final_model_path, "confusion_matrix.png")
plt.savefig(plot_path, dpi=300)
print(f"Confusion matrix plot saved to: {plot_path}")
plt.show()

# Log artifacts to W&B if enabled
if report_to == "wandb":
    print("Logging artifacts to W&B...")
    wandb.log({"confusion_matrix": wandb.Image(plt)})
    test_results_for_wandb = {f"test/{k}": v for k, v in evaluation_results.items()}
    wandb.summary.update(test_results_for_wandb)

"""# STEP 8: SAVE FINAL MODEL AND ASSETS
# Save the model's state, tokenizer, and emoji vocabulary for future use.
"""

print(f"\nSaving final model and assets to '{final_model_path}'...")
# For custom models, it's best to save the state dictionary
torch.save(model.state_dict(), os.path.join(final_model_path, "pytorch_model.bin"))
tokenizer.save_pretrained(final_model_path)
with open(os.path.join(final_model_path, "emoji_to_id.json"), 'w') as f:
    json.dump(emoji_to_id, f)
print("Model, tokenizer, and emoji vocab saved successfully.")

if report_to == "wandb":
    wandb.finish()
    print("W&B run finished.")

# --- Example of how to load the custom model back ---
# 1. Re-initialize the model architecture:
#    loaded_model = BertEmojiCrossAttentionModel(model_name, num_labels, EMOJI_VOCAB_SIZE, EMOJI_EMBEDDING_DIM)
#
# 2. Load the saved weights (state_dict):
#    state_dict = torch.load(os.path.join(final_model_path, "pytorch_model.bin"))
#    loaded_model.load_state_dict(state_dict)
#
# 3. Move model to the appropriate device:
#    device = 'cuda' if torch.cuda.is_available() else 'cpu'
#    loaded_model.to(device)
#    loaded_model.eval() # Set to evaluation mode

"""# Simpan ke Google Drive"""

from google.colab import drive
import os
import shutil

# Mount Google Drive
print("Mounting Google Drive...")
drive.mount('/content/drive')

# Tentukan path untuk menyimpan model di Google Drive
# Pastikan folder 'training 1' ada di root Google Drive Anda atau sesuaikan path
drive_save_path = "/content/drive/MyDrive/fine_tuned_indobert_EF_CrossAttn/training 8"

# Buat direktori jika belum ada
if not os.path.exists(drive_save_path):
    os.makedirs(drive_save_path)
    print(f"Direktori '{drive_save_path}' dibuat.")
else:
    print(f"Direktori '{drive_save_path}' sudah ada.")

# Tentukan path folder yang ingin disalin
source_folder = "/content/fine_tuned_cross_attention_model"

# Menyalin seluruh isi folder ke Google Drive
print(f"\nMenyalin isi folder '{source_folder}' ke '{drive_save_path}'...")
# Use shutil.copytree to copy the entire directory
try:
    # If directory already exists, remove it first to avoid errors
    if os.path.exists(drive_save_path):
      shutil.rmtree(drive_save_path)
    shutil.copytree(source_folder, drive_save_path)
    print("Isi folder berhasil disalin ke Google Drive.")
except Exception as e:
    print(f"Gagal menyalin folder: {e}")

# # Ini adalah kode sebelumnya untuk menyimpan model menggunakan trainer,
# # yang mungkin tidak menyalin semua file di folder.
# # trainer.save_model(drive_save_path)
# tokenizer.save_pretrained(drive_save_path) # Ini sudah disalin di copytree
# print("Model dan tokenizer berhasil disimpan di Google Drive.")